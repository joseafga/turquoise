require "json"
require "./types.cr"

module Turquoise
  class Eloquent
    module Chat
      # The base structured datatype containing multi-part content of a message.
      # See: https://ai.google.dev/api/caching#Content
      struct Content
        include JSON::Serializable
        # Optional. The producer of the content.
        property role : Role?
        # Ordered Parts that constitute a single message. Parts may have different MIME types.
        property parts = [] of Part
        # Internal handle to send images using telegram API
        @[JSON::Field(ignore: true)]
        property photo : String | File | Nil

        def initialize(text : String? = nil, @role = nil, @photo = nil)
          @parts << Part.new(text) unless text.nil?
        end

        # Markdown special character escaping
        def escape_md
          Helpers.escape_md to_s
        end

        def to_s
          io = IO::Memory.new

          parts.each do |part|
            next if part.text.nil?
            io << part.text.to_s << '\n'
          end

          io.to_s
        end

        enum Role
          User
          Model
        end
      end

      # A datatype containing media that is part of a multi-part `Content` message.
      # https://ai.google.dev/api/caching#Part
      struct Part
        include JSON::Serializable
        # Inline text.
        property text : String?

        # A predicted FunctionCall returned from the model that contains a string
        # representing the FunctionDeclaration.name with the arguments and their
        # values.
        @[JSON::Field(key: "functionCall")]
        property function_call : FunctionCall?

        # The result output of a `FunctionCall` that contains a string representing
        # the `FunctionDeclaration.name` and a structured JSON object containing any
        # output from the function is used as context to the model.
        @[JSON::Field(key: "functionResponse")]
        property function_response : FunctionResponse?

        # TODO: another properties
        # @[JSON::Field(key: "inlineData")]
        # property inline_data # Inline media bytes.
        # @[JSON::Field(key: "fileData")]
        # property file_data # URI based data.
        # @[JSON::Field(key: "executableCode")]
        # property executable_code # Code generated by the model that is meant to be executed.
        # @[JSON::Field(key: "codeExecutionResult")]
        # property code_execution_result # Result of executing the ExecutableCode.

        def initialize(@text = nil, @function_call = nil, @function_response = nil)
        end
      end

      # https://ai.google.dev/api/generate-content#method:-models.generatecontent
      struct Request
        include JSON::Serializable
        # Optional. Developer set `system instruction(s)`. Currently, text only.
        # https://ai.google.dev/gemini-api/docs/system-instructions
        @[JSON::Field(key: "systemInstruction")]
        property system_instruction : Chat::Content?

        # Required. The content of the current conversation with the model.
        # For single-turn queries, this is a single instance. For multi-turn queries
        # like chat, this is a repeated field that contains the conversation history
        # and the latest request.
        property contents : Deque(Chat::Content)

        # Optional. A list of Tools the Model may use to generate the next response.
        property tools : Array(Tool)?

        # Optional. Tool configuration for any Tool specified in the request. Refer
        # to the Function calling guide for a usage example.
        @[JSON::Field(key: "toolConfig")]
        property tool_config : ToolConfig?

        # Optional. A list of unique SafetySetting instances for blocking unsafe content.
        @[JSON::Field(key: "safetySettings")]
        property safety_settings : Array(SafetySetting)?

        # Optional. Configuration options for model generation and outputs.
        @[JSON::Field(key: "generationConfig")]
        property generation_config : GenerationConfig?

        # Optional. The name of the content [cached](https://ai.google.dev/gemini-api/docs/caching)
        # to use as context to serve the prediction.
        @[JSON::Field(key: "cachedContent")]
        property cached_content : String?

        # Configuration parameters are optional and non-initialized, so they must be
        # defined later
        def initialize(@system_instruction = nil, @tools = nil, @cached_content = nil)
          @contents = Deque(Chat::Content).new(MAX_MESSAGES)
        end

        # Keep maximum size and system message
        def <<(message : Chat::Content)
          contents.shift if contents.size >= MAX_MESSAGES
          contents.push message
        end

        # Configuration options for model generation and outputs. Not all parameters
        # are configurable for every model.
        # See: https://ai.google.dev/api/generate-content#generationconfig
        struct GenerationConfig
          include JSON::Serializable
          # Number of generated responses to return.
          @[JSON::Field(key: "candidateCount")]
          property candidate_count : Int32?

          # The set of character sequences (up to 5) that will stop output generation.
          # If specified, the API will stop at the first appearance of a stop sequence.
          # The stop sequence will not be included as part of the response.
          @[JSON::Field(key: "stopSequences")]
          property stop_sequences : Array(String)?

          # Controls the randomness of the output.
          # Values can range from [0.0,1.0], inclusive. A value closer to 1.0 will
          # produce responses that are more varied and creative, while a value closer
          # to 0.0 will typically result in more straightforward responses from the
          # model.
          property temperature : Float64?

          # The maximum number of tokens to include in a candidate.
          # If unset, this will default to output_token_limit specified in the model's
          # specification.
          @[JSON::Field(key: "maxOutputTokens")]
          property max_output_tokens : Int32?

          # The maximum number of tokens to consider when sampling.
          # The model uses combined Top-k and nucleus sampling.
          # Top-k sampling considers the set of top_k most probable tokens. Defaults to 40.
          @[JSON::Field(key: "topK")]
          property top_k : Int32?

          # The maximum cumulative probability of tokens to consider when sampling.
          # The model uses combined Top-k and nucleus sampling.
          # Tokens are sorted based on their assigned probabilities so that only the
          # most likely tokens are considered. Top-k sampling directly limits the
          # maximum number of tokens to consider, while Nucleus sampling limits number
          # of tokens based on the cumulative probability.
          @[JSON::Field(key: "topP")]
          property top_p : Float64?

          # Output response mimetype of the generated candidate text.
          # Supported mimetype:
          # - `text/plain`: (default) Text output.
          # - `application/json`: JSON response in the candidates.
          @[JSON::Field(key: "responseMimeType")]
          property response_mime_type : String?

          # Specifies the format of the JSON requested if response_mime_type is
          # `application/json`.
          @[JSON::Field(key: "responseSchema")]
          property response_schema : Nil # TODO

          def initialize(
            @stop_sequences = nil,
            @temperature = nil,
            @max_output_tokens = nil,
            @top_k = nil,
            @top_p = nil
          )
          end
        end
      end

      # Response from the model supporting multiple candidate responses.
      # See: https://ai.google.dev/api/generate-content#generatecontentresponse
      # TODO: promptFeedback
      struct Result
        include JSON::Serializable
        # Candidate responses from the model.
        getter candidates : Array(Candidate)

        # Returns the prompt's feedback related to the content filters.
        @[JSON::Field(key: "promptFeedback")]
        getter prompt_feedback : PromptFeedback?

        # Output only. Metadata on the generation requests' token usage.
        @[JSON::Field(key: "usageMetadata")]
        getter usage_metadata : UsageMetadata?

        @[JSON::Field(key: "modelVersion")]
        getter model_version : String?

        # A response candidate generated from the model.
        # See: https://ai.google.dev/api/generate-content#candidate
        struct Candidate
          include JSON::Serializable
          # Output only. Generated content returned from the model.
          property content : Chat::Content?

          # Optional. Output only. The reason why the model stopped generating tokens.
          # If empty, the model has not stopped generating tokens.
          @[JSON::Field(key: "finishReason")]
          property finish_reason : FinishReason?

          # List of ratings for the safety of a response candidate.
          # There is at most one rating per category.
          @[JSON::Field(key: "safetyRatings")]
          property safety_ratings : Array(SafetyRating)

          # TODO: citationMetadata - object (CitationMetadata)
          # Output only. Citation information for model-generated candidate.
          # This field may be populated with recitation information for any text included in the content. These are passages that are "recited" from copyrighted material in the foundational LLM's training data.

          # Output only. Token count for this candidate.
          @[JSON::Field(key: "tokenCount")]
          property token_count : Int32 = 0

          # TODO: avgLogprobs - number
          # Output only.
          # TODO: logprobsResult - object (LogprobsResult)
          # Output only. Log-likelihood scores for the response tokens and top tokens

          # Output only. Index of the candidate in the list of response candidates.
          property index : Int32 = 0
        end

        # A set of the feedback metadata the prompt specified in `Turquoise::Eloquent::Chat::Content`.
        # See: https://ai.google.dev/api/generate-content#PromptFeedback
        struct PromptFeedback
          include JSON::Serializable
          # Optional. If set, the prompt was blocked and no candidates are returned.
          @[JSON::Field(key: "blockReason")]
          getter block_reason : BlockReason?

          # Ratings for safety of the prompt. There is at most one rating per category.
          @[JSON::Field(key: "safetyRatings")]
          getter safety_ratings : Array(SafetyRating)
        end

        # Metadata on the generation request's token usage.
        # See: https://ai.google.dev/api/generate-content#UsageMetadata
        struct UsageMetadata
          include JSON::Serializable
          # Number of tokens in the prompt. When cachedContent is set, this is still
          # the total effective prompt size meaning this includes the number of tokens
          # in the cached content.
          @[JSON::Field(key: "promptTokenCount")]
          getter prompt_token_count : Int32?

          # Number of tokens in the cached part of the prompt (the cached content)
          @[JSON::Field(key: "cachedContentTokenCount")]
          getter cached_content_token_count : Int32?

          # Total number of tokens across all the generated response candidates.
          @[JSON::Field(key: "candidatesTokenCount")]
          getter candidates_token_count : Int32?

          # Total token count for the generation request (prompt + response candidates).
          @[JSON::Field(key: "totalTokenCount")]
          getter total_token_count : Int32
        end
      end

      # Tool details that the model may use to generate response.
      # https://ai.google.dev/api/caching#Tool
      struct Tool
        include JSON::Serializable
        # Optional. A list of `FunctionDeclarations` available to the model that can
        # be used for function calling.
        @[JSON::Field(key: "functionDeclarations")]
        property function_declarations : Array(FunctionDeclaration)?

        # TODO: Optional. Enables the model to execute code as part of generation.
        # @[JSON::Field(key: "codeExecution")]
        # property code_execution : CodeExecution

        def initialize
        end
      end

      # Structured representation of a function declaration as defined by the
      # OpenAPI 3.03 specification.
      # https://ai.google.dev/api/caching#FunctionDeclaration
      struct FunctionDeclaration
        include JSON::Serializable
        # Required. The name of the function.
        property name : String
        # Required. A brief description of the function.
        property description : String
        # Optional. Describes the parameters to this function.
        property parameters : Schema?

        def initialize(@name, @description, @parameters = nil)
        end

        def initialize(@name, @description, parameters : NamedTuple)
          @parameters = Schema.new(**parameters)
        end

        # Reduced scheme
        struct Schema
          include JSON::Serializable
          # Required. Data type.
          property type : Type
          # Optional. A brief description of the parameter. This could contain
          # examples of use. Parameter description may be formatted as Markdown.
          property description : String?
          # Optional. Properties of Type
          property properties : Hash(String, Schema)?
          # Optional. Required properties of Type
          property required : Array(String)?

          # TODO: format - string
          # Optional. The format of the data. This is used only for primitive datatypes. Supported formats: for NUMBER type: float, double for INTEGER type: int32, int64 for STRING type: enum
          # TODO: nullable - boolean
          # Optional. Indicates if the value may be null.
          # TODO: enum[] - string
          # Optional. Possible values of the element of Type.STRING with enum format. For example we can define an Enum Direction as : {type:STRING, format:enum, enum:["EAST", NORTH", "SOUTH", "WEST"]}
          # TODO: maxItems - string (int64 format)
          # Optional. Maximum number of the elements for Type.ARRAY.
          # TODO: minItems - string (int64 format)
          # Optional. Minimum number of the elements for Type.ARRAY.
          # TODO: items - object (Schema)
          # Optional. Schema of the elements of Type.ARRAY.

          def initialize(@type, @description = nil, @properties = nil, @required = nil)
          end
        end
      end

      # A predicted `FunctionCall` returned from the model that contains a string
      # representing the `FunctionDeclaration.name` with the arguments and their
      # values.
      struct FunctionCall
        include JSON::Serializable
        # Required. The name of the function to call.
        property name : String
        # Optional. The function parameters and values in JSON object format.
        property args : JSON::Any?

        def initialize(@name, @args = nil)
        end
      end

      # This should contain the result of a `FunctionCall` made based on model
      # prediction.
      # https://ai.google.dev/api/caching#FunctionResponse
      struct FunctionResponse
        include JSON::Serializable
        # Required. The name of the function to call.
        property name : String
        # Required. The function response in JSON object format.
        property response : JSON::Any

        def initialize(@name, @response)
        end
      end

      # The Tool configuration containing parameters for specifying Tool use in the request.
      # https://ai.google.dev/api/caching#ToolConfig
      struct ToolConfig
        include JSON::Serializable
        # Optional. Function calling config.
        @[JSON::Field(key: "functionCallingConfig")]
        property function_calling_config : FunctionCallingConfig?
      end

      struct FunctionCallingConfig
        include JSON::Serializable
        # Optional. Specifies the mode in which function calling should execute.
        property mode : Mode?

        # Optional. A set of function names that, when provided, limits the
        # functions the model will call.
        @[JSON::Field(key: "allowedFunctionNames")]
        property allowed_function_names : Array(String)?
      end
    end

    # Simplified error response
    struct Error
      include JSON::Serializable
      getter code : Int32
      getter message : String
      getter status : String
    end

    module Prompt
      struct Request
        include JSON::Serializable
        property prompt : String
        property image : File?
        property mask : File?
        property num_steps : Int32?
        property strength : Int32?
        property guidance : Float32?

        def initialize(@prompt, @num_steps = nil)
        end
      end
    end
  end
end
